[runpod]
# RunPod Hub Template Configuration
# Qwen3-ASR Serverless - Speech Recognition

name = "qwen3-asr-api"
dockerfile = "Dockerfile"

# GPU Requirements (16GB VRAM minimum for Qwen3-ASR-1.7B)
gpu_types = ["NVIDIA RTX A4000", "NVIDIA RTX A5000", "NVIDIA GeForce RTX 4090", "NVIDIA L4", "NVIDIA L40", "NVIDIA A10", "NVIDIA A40", "NVIDIA A100-SXM4-40GB", "NVIDIA A100-SXM4-80GB"]
min_vram_gb = 16

# Storage Configuration
container_disk_gb = 5    # Code and dependencies
volume_gb = 20           # Model cache (persistent across workers)

# Execution Settings
execution_timeout = 300  # 5 minutes per job

# Auto-scaling Configuration
min_workers = 0          # Scale to zero when idle
max_workers = 5          # Maximum concurrent workers
scale_down_delay = 60    # Seconds before scaling down
